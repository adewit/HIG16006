#This file collects up to date instructions for running the 13 TeV MSSM statistical results. For more detailed information on Combine Harvester please see the documentation at
http://cms-analysis.github.io/CombineHarvester/

1a) Setting up datacards: for model independent limits

MorphingMSSMRun2 --output_folder="mssm_120516_unblinding" -m MH  --postfix="-mtsv" --control_region=1 --auto_rebin=true --real_data=true

This will setup a subdirectory for each channel-cat, as well as combined channel and full combination directories. Each directory contains a single combined card as generated by WriteCards.
Note that this uses the new RooMorphingPdf and includes bin-by-bin uncertainties which are merged with merging parameter 0.4. Optional extras are controlled by --auto_rebin for automatic rebinning, --manual_rebin to choose a rebinning manually. 

1b) Setting up datacards: for model dependent limits

MorphingMSSMRun2 --output_folder="mssm_120516_unblinding_mhmodp" -m MH  --postfix="-mtsv" --control_region=1

If not using the argument -m MH, the code will setup datacards for all 3 Higgs bosons as required for model dependent limits

2a) Setting up workspaces for model independent limits 

Workspaces can be setup using the combine tool text2workspace, but this is now implemented in combineTool.py for easy conversion of multiple datacards:

combineTool.py -M T2W -o "ggPhi.root" -P CombineHarvester.CombinePdfs.ModelIndependent:floatingMSSMXSHiggs --PO 'modes=ggH' --PO 'ggHRange=0:20' -i output/mssm_120516_unblinding/*
combineTool.py -M T2W -o "bbPhi.root" -P CombineHarvester.CombinePdfs.ModelIndependent:floatingMSSMXSHiggs --PO 'modes=bbH' --PO 'bbHRange=0:20' -i output/mssm_120516_unblinding/*

This will apply the text2workspace step recursively, setting up for every subdirectory and hence every channel-cat scenario. Workspaces are created for each of the two signal cases. In each case, the other signal is profiled. There are many different options to combineTool, but this particular set will create a "combined card" named combined.txt.cmb in each subdir, and a workspace named as required, either ggPhi.root or bbPhi.root


2a) Setting up workspaces for model dependent limits 

combineTool.py -M T2W -o "mhmodp.root" -P CombineHarvester.CombinePdfs.MSSM:MSSM --PO filePrefix=$CMSSW_BASE/src/auxiliaries/models/ --PO modelFiles=13TeV,mhmodp_mu200_13TeV.root,1 -i output/mssm_120516_unblinding_mhmodp/*

This will perform the same recursive application of text2workspace, this time applying the mhmodp physics model.

3a) Running model independent limits

This can be done directly with combine, but again combineTool makes life a lot easier for us by allowing successive calls (with different choices of job submission, and parallelisation of calculations):

combineTool.py -m "90,100,110,120,130,140,160,180,200,250,300,350,400,450,500,600,700,800,900,1000,1200,1400,1500,1600,1800,2000,2300,2600,2900,3200" -M Asymptotic --boundlist input/mssm_boundaries.json  --setPhysicsModelParameters r_ggH=0,r_bbH=0  -d output/mssm_120516_unblinding/*/ggPhi.root --there -n ".ggH"

combineTool.py -m "90,100,110,120,130,140,160,180,200,250,300,350,400,450,500,600,700,800,900,1000,1200,1400,1500,1600,1800,2000,2300,2600,2900,3200" -M Asymptotic --boundlist input/mssm_boundaries.json  --setPhysicsModelParameters r_ggH=0,r_bbH=0  -d output/mssm_120516_unblinding/*/bbPhi.root --there -n ".bbH"

This goes to each subdirectory of output/mssm_120516_unblinding/ (--there) and performs the combine calculation for the masses listed on the workspace (either ggH or bbH workspace). The combine output files are stored in the directories alongside the datacards. Note the optin --parallel = X allows you to run the calculations interactively with X in parallel, and e.g.' --job-mode 'lxbatch' --task-name 'mssm_ggH' --sub-opts '-q 1nh' --merge=4 ' could be used to instead run on the lxbatch, merging 4 masspoints into 1 job and submitting to the 1 hour queue.

Once all calculations are complete, the results are collected into json files using:

combineTool.py -M CollectLimits output/mssm_120516_unblinding/*/higgsCombine.ggH*.root --use-dirs -o "mssm_120516_unblinding_ggH.json"

combineTool.py -M CollectLimits output/mssm_120516_unblinding/*/higgsCombine.bbH*.root --use-dirs -o "mssm_120516_unblinding_bbH.json"

This will place a json in the current directory, and append the string "mssm_120516_unblinding_ggH" to them. One will be placed for every subdir, so every channel-cat, combination requested will be available then for plotting.

3b) Running model dependent limits

combineTool.py -M AsymptoticGrid ../CombinePdfs/scripts/mssm_asymptotic_grid.json -d output/mssm_120516_unblinding_mhmodp/mt/mhmodp.root  --job-mode 'interactive' --task-name 'mssm_mhmodp'

The asymptotic grid mode reads in an input json to define a set of mA-tanb points to scan and perform the limit calculation for. This time the calculation is done once per workspace, since the script has a nice feature which is that if you call it multiple times with the same workspace and asymptotic grid it will check which points have already completed successfully and only run those remaining. This makes it really easy to top up the grid for a finer scan for example. Once all points are complete, on the final call the script will create asymptotic_grid.root file containing the results.

4a) Plotting model independent limits

The usual Brazil band plots can be made using this script, for e.g. the mutau channel:

python scripts/plotMSSMLimits.py --logy --logx mssm_120516_unblinding_ggH_mt.json --show exp --cms-sub="Preliminary" -o mssm_120516_unblinding_mt

Or comparison plots can be made using the following script:

python scripts/MSSMlimitCompare.py --file=mssm_120516_unblinding_ggH_mt.json,mssm_120516_unblinding_ggH_et.json --labels="mutau,etau" --expected_only --outname="mssm_120516_unblinding_mt_vs_et_ggH" --process="gg#phi" 

The options --absolute and --relative can be used to make ratio plots as well. Note that it is also possible to apply parton luminosity scale factors to any of the limits.

4a) Plotting model dependent limits

python ../CombineTools/scripts/plotLimitGrid.py asymptotic_grid.root --scenario-label="m_{h}^{mod+} scenario"  --output="mssm_120516_unblinding_mhmodp_mt" --title-right="2.2 fb^{-1} (13 TeV)" --expected_only

The plotting takes thr asymptotic_grid file as input, and performs interpolation to produce smooth contours of exclusion for a 2D mA-tanb plot. Note that this script contains many different optional settings for this interpolation. 

5) Prefit plots

Prefit plots can be made and either the model dependent (3 Higgs) or signal resonance signal can be added for a benchmark point. The usage:
 
PostFitShapesFromWorkspace -d output/mssm_120516_unblinding//htt_mt_8_13TeV/htt_mt_8_13TeV.txt -w output/mssm_120516_unblinding/htt_mt_8_13TeV/ggPhi.root -o htt_mt_8_13TeV_shapes_080416.root --print --freeze r_ggH=0.1,r_bbH=0.1,MH=700
python scripts/postFitPlot.py --file=htt_mt_8_13TeV_shapes_080416.root --ratio --extra_pad=0.3 --custom_x_range --x_axis_max=999.9 --x_axis_min=0.0 --r_ggH=0.1 --r_bbH=0.1 --mPhi=700 --file_dir="htt_mt_8_13TeV"

First is a call to PostFitShapesFromWorkspace, which will generate the signal and background templates for the benchmark point of mPhi = 700 GeV and for cross-section values for the 2 signal processes of 0.1pb. The script will then make a stacked plot. The option --model_dep can be used with choices for --mA and --tanb to instead plot the 3 Higgs signal from a model dependent workspace. 

By default (essentially hardcoded until we pass preapproval) the data will be blinded above 200 GeV. Automated blinding, based on s/root b bigger than 0.5 in a given bin, is also implemented and can be enable. The option --auto_blind_check_only will simply report which bins the calculation would choose to blind, based on internally running PostFitShapesFromWorkspace for a few benchmark points, whilst keeping the manual blinding of 200 and above. The option --auto_blind will then actually apply the blinding based on the s/root b calculation. To be used with caution - please call the check_only mode first to check it appears sensible! To simply make an s/root b plot for a given benchmark signal, the option --soverb_plot can be used, which replaces the ratio with the s/root b plot for signal and doesnt plot ANY data.

6) Postfit plots

Postfit plots require a sensible choice of fit. You can choose either the model independent or model dependent workspace, and simply need to set the appropriate parameters to soemthign sensible, e.g: 

combineTool.py -M MaxLikelihoodFit -t -1 --setPhysicsModelParameters MH=700,r_ggH=0.1,r_bbH=0.1 --expectSignal 1 --skipBOnlyFit -d output/mssm_120516_unblinding/cmb/ggPhi.root --out=output/mssm_120516_unblinding/cmb/out 

The plotting code can then be used in postfit mode and passed the output of the maximum likelihood fit, to make post fit plots instead of prefit:

PostFitShapesFromWorkspace -d output/mssm_120516_unblinding//htt_mt_8_13TeV/htt_mt_8_13TeV.txt -w output/mssm_120516_unblinding/htt_mt_8_13TeV/ggPhi.root -o htt_mt_8_13TeV_shapes_080416_postfit.root --print --freeze r_ggH=0.1,r_bbH=0.1,MH=700 --postfit --sampling -f output/mssm_120516_unblinding/cmb/out/mlfit.Test.root:fit_s
python scripts/postFitPlot.py --file=htt_mt_8_13TeV_shapes_080416_postfit.root --ratio --extra_pad=0.3 --custom_x_range --x_axis_max=999.9 --x_axis_min=0.0 --r_ggH=0.1 --r_bbH=0.1 --mPhi=700 --file_dir="htt_mt_8_13TeV" --fitresult=output/mssm_120516_unblinding/cmb/out/mlfit.Test.root --mode="postfit"

7) Postfit plots for unblinding

cd output/mssm_120516_unblinding/cmb
combine -M MaxLikelihoodFit -d ggPhi.root -m 700 --setPhysicsModelParameters r_ggH=0.1,r_bbH=0.1 --setPhysicsModelParameterRanges r_ggH=-3,3:r_bbH=-3,3 --minimizerTolerance 0.01 --robustFit 1  --minimizerAlgoForMinos Minuit2,Migrad
PostFitShapesFromWorkspace -d combined.txt.cmb -w ggPhi.root -o shapes.root --print --freeze r_ggH=0.1,r_bbH=0.1,MH=700 --postfit --sampling -f mlfit.root:fit_s
cd -
cp output/mssm_120516_unblinding/cmb/shapes.root ./
python scripts/makeMassPlots.py

8) creating datacards for pulls and GOF tests

MorphingMSSMRun2 --output_folder="mssm_120516_unblinding" -m MH  --postfix="-mtsv" --control_region=1 --auto_rebin=true --real_data=true

For creating the workspace from the datacards we use the default model. This allows easier handling for the b-only fit.

combineTool.py -M T2W -o "ws.root" -i output/mssm_120516_unblinding/*

8a) Running the GoF jobs

We look at the Goodness of Fit for three different algorithms. The saturated model (saturated), Anderson-Darling (AD) and Kolmogorow-Smirnow (KS).
For the AD and KS it is sufficient to run the fits for the combined cards as the test-statitic for the individual channels can be extracted from these results. For the saturated model it is necessary to run them independtly of each other.
The choice of the mass value as 160 is arbitrary and not of any relevance here as we look at background only fits,

ALGO=AD (or ALGO=KS, ALGO=saturated)
combineTool.py -M GoodnessOfFit --algorithm $ALGO -m 160 --there -d output/mssm_120516_unblinding/cmb/ws.root -n ".$ALGO.toys" --fixedSignalStrength=0 -t 500
combineTool.py -M GoodnessOfFit --algorithm $ALGO -m 160 --there -d output/mssm_120516_unblinding/cmb/ws.root -n ".$ALGO" --fixedSignalStrength=0

ALGO=saturated
combineTool.py -M GoodnessOfFit --algorithm $ALGO -m 160 --there -d output/mssm_120516_unblinding/*_13TeV/ws.root -n ".$ALGO.toys" --fixedSignalStrength=0 -t 500
combineTool.py -M GoodnessOfFit --algorithm $ALGO -m 160 --there -d output/mssm_120516_unblinding/*_13TeV/ws.root -n ".$ALGO" --fixedSignalStrength=0

The toys can also be split in multiple batches by adding e.g. -s 0:10:1 as option (setting the seed to be 0-10 in 11 jobs)

8b) Collecting GoF outputs

For the saturated model run for each category seperatly

combineTool.py -M CollectGoodnessOfFit --input output/mssm_120516_unblinding/htt_et_8_13TeV/higgsCombine.saturated.GoodnessOfFit.mH160.root --input-toys output/mssm_120516_unblinding/htt_et_8_13TeV/higgsCombine.saturated.toys.GoodnessOfFit.mH160.*.root -o htt_et_8_13TeV_saturated.json

For the AD and KS run

ALGO=AD (or ALGO=KS)
combineTool.py -M CollectGoodnessOfFit --input output/mssm_120516_unblinding/cmb/higgsCombine.$ALGO.GoodnessOfFit.mH160.root --input-toys output/mssm_120516_unblinding/cmb/higgsCombine.$ALGO.toys.GoodnessOfFit.mH160.*.root -o cmb_$ALGO.json

8c) Plotting the GoF results

For the saturated model you again need to run the plotting once per cateogry like

python CombineTools/scripts/plotGof.py --statistic saturated --mass 160.0 -o htt_et_9_13TeV-saturated htt_et_9_13TeV_saturated.json  --title-right="2.3 fb^{-1} (13 TeV)" --title-left="e#tau_{h}, btag"

For the AD or KS algorithm the plotting is done for all categories in one go (inclusing labelling of the plots)

ALGO=AD (or ALGO=KS)
python CombineTools/scripts/plotGof.py --statistic $ALGO --mass 160.0 cmb_$ALGO.json --title-right="2.3 fb^{-1} (13 TeV)" --output='-$ALGO'

8d) Getting the pulls

For determining the pulls in the b-only fit we run

combineTool.py -M MaxLikelihoodFit output/mssm_120516_unblinding/cmb/ws.root

From this point on the pulls can then be extracted using the script diffNuisances.py which is provided together with combine.
WARNING: the version provided with combine includes informations about the b-only and the s+b fit. These are also saved to the output. The current workaround is to use a modified version which ignores the s+b fit.
python $CMSSW_BASE/src/HiggsAnalysis/CombinedLimit/test/diffNuisances.py -A -a --stol 0.99 --stol 0.99 --vtol 99. --vtol2 99. -f html mlfit.Test.root > mlfit.html
